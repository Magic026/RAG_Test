# src/query_engine.py
from llama_index.core import StorageContext, load_index_from_storage
from llama_index.multi_modal import MultiModalVectorStoreIndex
from llama_index.llms.huggingface import HuggingFaceLLM
from llama_index.embeddings.open_clip import OpenCLIPEmbedding
import torch


class MultimodalQueryEngine:
    def __init__(self, index_dir="index", llm_model="Qwen/Qwen-VL-Chat"):
        self.index_dir = index_dir
        self.llm_model = llm_model
        self.engine = None
        self._initialize_engine()

    def _initialize_engine(self):
        print("ğŸ”„ åŠ è½½å¤šæ¨¡æ€ç´¢å¼•...")
        storage_context = StorageContext.from_defaults(persist_dir=self.index_dir)
        index = load_index_from_storage(
            storage_context,
            embed_model=OpenCLIPEmbedding(model_name="ViT-B-32", device="cuda"),
        )

        print("ğŸš€ åŠ è½½ Qwen2.5-VL-72b æ¨¡å‹...")
        llm = HuggingFaceLLM(
            model_name=self.llm_model,
            tokenizer_name=self.llm_model,
            device_map="cuda",
            model_kwargs={
                "trust_remote_code": True,
                "torch_dtype": torch.bfloat16,
                "max_memory": {0: "20GiB", "cpu": "32GiB"} if torch.cuda.is_available() else None,
            },
            generate_kwargs={"max_new_tokens": 256, "temperature": 0.3},
        )

        self.engine = index.as_query_engine(
            llm=llm,
            similarity_top_k=3,
            text_qa_template=(
                "è¯·æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚"
                "å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·å›ç­”â€œæ— æ³•ç¡®å®šâ€ã€‚"
                "è¯·å°½é‡å¼•ç”¨å›¾è¡¨æˆ–æ–‡æœ¬ä¸­çš„å…·ä½“ä¿¡æ¯ï¼Œå¹¶è¯´æ˜æ¥æºé¡µç ã€‚\n\n"
                "ä¸Šä¸‹æ–‡ï¼š{context_str}\n\n"
                "é—®é¢˜ï¼š{query_str}\n\n"
                "ç­”æ¡ˆï¼š"
            ),
        )

    def query_with_source(self, question):
        response = self.engine.query(question)

        # æå–æ¥æºä¿¡æ¯
        source_pages = []
        source_files = []
        for node in response.source_nodes:
            meta = node.node.metadata
            source_pages.append(meta.get("page_label", "æœªçŸ¥"))
            source_files.append(meta.get("file_name", "æœªçŸ¥"))

        # æ¨æµ‹æœ€å¯èƒ½çš„æ¥æºï¼ˆå–ç¬¬ä¸€ä¸ªï¼‰
        filename = source_files[0] if source_files else "æœªçŸ¥"
        page = int(source_pages[0]) if source_pages and source_pages[0].isdigit() else 1

        return {
            "answer": str(response),
            "filename": filename,
            "page": page,
            "raw_response": response,
            "sources": [{"filename": f, "page": p} for f, p in zip(source_files, source_pages)]
        }
